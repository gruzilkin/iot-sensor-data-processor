{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "! pip install psycopg2\n",
                "! pip install cachetools\n",
                "! pip install pandas\n",
                "! pip install seaborn\n",
                "\n",
                "import psycopg2\n",
                "import psycopg2.extras\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "import heapq as hq\n",
                "\n",
                "from cachetools import cached, TTLCache\n",
                "\n",
                "import time"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set(rc={'figure.figsize':(15, 10)})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_connection():\n",
                "    dbname = 'postgres'\n",
                "    user = 'postgres'\n",
                "    password = 'postgres'\n",
                "    host = '192.168.11.2'\n",
                "    return psycopg2.connect(dbname=dbname, user=user, password=password, host=host)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def fetch_devices(connection, sensor):\n",
                "\twith connection.cursor() as cursor:\n",
                "\t\tcursor.execute(f\"\"\"SELECT DISTINCT device_id FROM sensor_data_{sensor}\"\"\")\n",
                "\t\treturn [row[0] for row in cursor.fetchall()]\n",
                "\n",
                "def fetch_tail(connection, sensor, signal, device_id, include_timestamp=False):\n",
                "\twith connection.cursor() as cursor:\n",
                "\t\tsql = f\"\"\"WITH last_received_at AS (\n",
                "\t\t\t\t\tSELECT MAX(received_at) as last_received_at\n",
                "\t\t\t\t\tFROM sensor_data_{sensor}\n",
                "\t\t\t\t\tJOIN weights_{sensor}_{signal} USING (id)\n",
                "\t\t\t\t\tWHERE device_id = %s\n",
                "\t\t\t\t), last_peak AS (\n",
                "\t\t\t\t\tSELECT *\n",
                "\t\t\t\t\tFROM sensor_data_{sensor}\n",
                "\t\t\t\t\tJOIN weights_{sensor}_{signal} USING (id)\n",
                "\t\t\t\t\tWHERE device_id = %s\n",
                "\t\t\t\t\tAND received_at > (SELECT last_received_at - interval '5 minute'  FROM last_received_at)\n",
                "\t\t\t\t\tORDER BY weight DESC\n",
                "\t\t\t\t\tLIMIT 1\n",
                "\t\t\t\t)\n",
                "\t\t\t\tSELECT id, {signal} as signal\n",
                "\t\t\t\tFROM sensor_data_{sensor}\n",
                "\t\t\t\tWHERE device_id = %s AND id >= COALESCE((SELECT id FROM last_peak), 0)\"\"\"\n",
                "\t\tcursor.execute(sql, (device_id, device_id, device_id,))\n",
                "\t\t\n",
                "\t\tcolumns = ['id', 'signal']\n",
                "\t\tif include_timestamp:\n",
                "\t\t\tcolumns.append('received_at')\n",
                "\t\treturn pd.DataFrame.from_records(cursor.fetchall(), index=['id'], columns=columns)\n",
                "\n",
                "def fetch(connection, sensor, signal, device_id, include_timestamp=False):\n",
                "\twith connection.cursor() as cursor:\n",
                "\t\tsql = f\"\"\"SELECT id, {signal} as signal {', received_at ' if include_timestamp else ''} \n",
                "\t\t\tFROM sensor_data_{sensor}\n",
                "\t\t\tWHERE device_id = %s AND received_at > now() - interval '1 day'\n",
                "\t\t\tORDER BY received_at ASC\"\"\"\n",
                "\t\tcursor.execute(sql, (device_id,))\n",
                "\t\t\n",
                "\t\tcolumns = ['id', 'signal']\n",
                "\t\tif include_timestamp:\n",
                "\t\t\tcolumns.append('received_at')\n",
                "\t\treturn pd.DataFrame.from_records(cursor.fetchall(), index=['id'], columns=columns)\n",
                "\n",
                "def fetch_smart_ui(connection, sensor, signal, device_id, percentile):\n",
                "\twith connection.cursor() as cursor:\n",
                "\t\tsql = f\"\"\"WITH top_weights AS (\n",
                "\t\t\t\t\tSELECT id, {signal} as signal, received_at, PERCENT_RANK() OVER (ORDER BY weight DESC) percentile\n",
                "\t\t\t\t\tFROM sensor_data_{sensor}\n",
                "\t\t\t\t\tJOIN weights_{sensor}_{signal} USING (id)\n",
                "\t\t\t\t\tWHERE device_id = %s\n",
                "\t\t\t\t)\n",
                "\t\t\t\t(SELECT id, {signal} as signal, received_at\n",
                "\t\t\t\tFROM sensor_data_{sensor}\n",
                "\t\t\t\tWHERE device_id = %s\n",
                "\t\t\t\tORDER BY id ASC LIMIT 1)\n",
                "\t\t\t\tUNION\n",
                "\t\t\t\t(SELECT id, signal, received_at\n",
                "\t\t\t\tFROM top_weights\n",
                "\t\t\t\tWHERE percentile < %s)\n",
                "\t\t\t\tUNION\n",
                "\t\t\t\t(SELECT id, {signal} as signal, received_at\n",
                "\t\t\t\tFROM sensor_data_{sensor}\n",
                "\t\t\t\tWHERE device_id = %s\n",
                "\t\t\t\tORDER BY id DESC LIMIT 1)\"\"\"\n",
                "\t\tcursor.execute(sql, (device_id, device_id, percentile, device_id,))\n",
                "\t\t\n",
                "\t\tcolumns = ['id', 'signal', 'received_at']\n",
                "\t\treturn pd.DataFrame.from_records(cursor.fetchall(), index=['id'], columns=columns)\n",
                "\n",
                "def fetch_statistics(connection, sensor, signal, device_id):\n",
                "\twith connection.cursor() as cursor:\n",
                "\t\tsql = f\"\"\"SELECT avg({signal}), stddev_pop({signal}) FROM sensor_data_{sensor} WHERE device_id = %s\"\"\"\n",
                "\t\tcursor.execute(sql, (device_id,))\n",
                "\t\treturn cursor.fetchone()\n",
                "\n",
                "def fetch_weights(connection, sensor, signal, device_id):\n",
                "\twith connection.cursor() as cursor:\n",
                "\t\tsql = f\"\"\"\tSELECT id, weight\n",
                "\t\t\t\t\tFROM sensor_data_{sensor}\n",
                "\t\t\t\t\tJOIN weights_{sensor}_{signal} USING (id)\n",
                "\t\t\t\t\tWHERE device_id = %s\n",
                "\t\t\t\t\tORDER BY id\"\"\"\n",
                "\t\tcursor.execute(sql, (device_id,))\n",
                "\n",
                "\t\tcolumns = ['id', 'weight']\n",
                "\t\tdf = pd.DataFrame.from_records(cursor.fetchall(), index=['id'], columns=columns)\n",
                "\t\tdf.weight = df.weight.astype('float')\n",
                "\t\treturn df\n",
                "\n",
                "def fetch_scd30_ppm():\n",
                "\twith create_connection() as connection:\n",
                "\t\treturn fetch(connection, 'scd30', 'ppm', 'zero', include_timestamp=True)\n",
                "\n",
                "def fetch_scd30_ppm_smart(percentile=0.1):\n",
                "\twith create_connection() as connection:\n",
                "\t\treturn fetch_smart_ui(connection, 'scd30', 'ppm', 'zero', percentile=percentile)\n",
                "\n",
                "def fetch_scd30_ppm_weights():\n",
                "\twith create_connection() as connection:\n",
                "\t\treturn fetch_weights(connection, 'scd30', 'ppm', 'zero')\n",
                "\n",
                "def fetch_sgp40_voc():\n",
                "\twith create_connection() as connection:\n",
                "\t\treturn fetch(connection, 'sgp40', 'voc', 'zero', include_timestamp=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def remove_old_data(connection, sensor):\n",
                "\twith connection.cursor() as cursor:\n",
                "\t\tcursor.execute(f\"\"\"DELETE FROM sensor_data_{sensor}\n",
                "\t\tWHERE received_at < now() - interval '1 day'\"\"\")\n",
                "\n",
                "def update_weight(connection, sensor, signal, series):\n",
                "\twith connection.cursor() as cursor:\n",
                "\t\tsql = f\"\"\"INSERT INTO weights_{sensor}_{signal} (id, weight) VALUES %s\n",
                "\t\tON CONFLICT (id) DO UPDATE SET weight = EXCLUDED.weight\n",
                "\t\tWHERE weights_{sensor}_{signal}.weight < EXCLUDED.weight\"\"\"\n",
                "\t\tdata = [(id, weight) for id, weight in series.items()]\n",
                "\t\tpsycopg2.extras.execute_values(cursor, sql, data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_weights(data, ratio = 1):\n",
                "    y = data\n",
                "    x = np.arange(len(y))\n",
                "    indeces = {0:0, len(y)-1:0}\n",
                "\n",
                "    processed = 2\n",
                "    limit = max(10, int(len(data) * ratio))\n",
                "\n",
                "    queue = []\n",
                "    hq.heappush(queue, (0, (0, len(y)-1)))\n",
                "\n",
                "    while queue and processed < limit:\n",
                "        _, (left, right) = hq.heappop(queue)\n",
                "\n",
                "        if right - left == 1:\n",
                "            continue\n",
                "\n",
                "        y_range = y[left:right + 1]\n",
                "        x_range = x[left:right + 1]\n",
                "        \n",
                "        x1, y1, x2, y2 = x_range[0], y_range[0], x_range[-1], y_range[-1]\n",
                "        a = (y2 - y1) / (x2 - x1)\n",
                "        b = -x1 * (y2 - y1) / (x2 - x1) + y1\n",
                "        y_hat = a*x_range + b\n",
                "        diff = np.abs(y_range - y_hat)\n",
                "        diff = diff[1:-1]\n",
                "\n",
                "        i = np.argmax(diff)\n",
                "        error = diff[i]\n",
                "        i += left + 1\n",
                "\n",
                "        indeces[i] = error\n",
                "        hq.heappush(queue, (-error, (left, i)))\n",
                "        hq.heappush(queue, (-error, (i, right)))\n",
                "        processed += 1 \n",
                "\n",
                "    indeces = dict(sorted(indeces.items(), key=lambda item: item[0]))\n",
                "    return np.array([indeces[x] if x in indeces.keys() else 0 for x in x])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_weights_for_series(series, ratio=1):\n",
                "    data = series.to_numpy()\n",
                "    start = time.time()\n",
                "    weight = calculate_weights(data, ratio)\n",
                "    end = time.time()\n",
                "    print(f\"weight calculation took {end-start:.2f}\")\n",
                "\n",
                "    return pd.Series(index=series.index, data=weight)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_weights():\n",
                "    sensors = {'scd30': ['ppm', 'temperature', 'humidity'],'sgp40': ['voc']}\n",
                "    with create_connection() as connection:\n",
                "        for sensor, signals in sensors.items():\n",
                "            remove_old_data(connection, sensor)\n",
                "            devices = fetch_devices(connection, sensor)\n",
                "            for signal in signals:\n",
                "                for device in devices:\n",
                "                    df = fetch_tail(connection, sensor, signal, device)\n",
                "                    \n",
                "                    print(f\"{sensor}/{signal}/{device} tail length {len(df)}\")\n",
                "                    \n",
                "                    df.signal = df.signal.astype(float)\n",
                "                    \n",
                "                    mean, std = fetch_statistics(connection, sensor, signal, device)\n",
                "                    df.signal = (df.signal - float(mean)) / float(std)\n",
                "                    \n",
                "                    weights = calculate_weights_for_series(df.signal)\n",
                "                    weights = weights[weights > 0]\n",
                "                    update_weight(connection, sensor, signal, weights)\n",
                "        connection.commit()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "weights = fetch_scd30_ppm_weights()\n",
                "weights['log_weight'] = np.log(weights.weight)\n",
                "#sns.histplot(data=weights, x=\"log_weight\")\n",
                "\n",
                "mean_weight = np.mean(weights.weight)\n",
                "median_weight = np.median(weights.weight)\n",
                "mean_log_weight = np.mean(weights.log_weight)\n",
                "median_log_weight = np.median(weights.log_weight)\n",
                "\n",
                "print(f\"mean: {mean_weight}, median: {median_weight}, mean_log: {mean_log_weight}, median_log:{median_log_weight}\")\n",
                "\n",
                "print(len(weights.weight[weights.weight > mean_weight]))\n",
                "print(len(weights.weight[weights.weight > median_weight]))\n",
                "print(len(weights.log_weight[weights.log_weight > mean_log_weight]))\n",
                "print(len(weights.log_weight[weights.log_weight > median_log_weight]))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "smart = fetch_scd30_ppm_smart(percentile=1)\n",
                "smart['type'] = 'smart'\n",
                "original = fetch_scd30_ppm()\n",
                "original['type'] = 'original'\n",
                "print(len(smart), len(original))\n",
                "graph = pd.concat([original, smart], ignore_index=True)\n",
                "sns.lineplot(data=graph, x='received_at', y='signal', hue='type')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "process_weights()"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "c7509e2d30a69c0d6453c004c8c279db9db69b9204abb78224cf08720a2badfc"
        },
        "kernelspec": {
            "display_name": "Python 3.8.3 ('torch')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.3"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
