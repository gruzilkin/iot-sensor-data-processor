{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "! pip install psycopg2\r\n",
                "! pip install sklearn\r\n",
                "! pip install cachetools\r\n",
                "\r\n",
                "import psycopg2\r\n",
                "\r\n",
                "import numpy as np\r\n",
                "\r\n",
                "from sklearn.pipeline import make_pipeline\r\n",
                "from sklearn.model_selection import train_test_split, ParameterGrid\r\n",
                "from sklearn.preprocessing import StandardScaler\r\n",
                "from sklearn.preprocessing import PolynomialFeatures\r\n",
                "from sklearn.linear_model import LinearRegression\r\n",
                "\r\n",
                "from cachetools import cached, TTLCache"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "device_id = \"iskra\""
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def create_connection():\r\n",
                "    dbname = 'postgres'\r\n",
                "    user = 'postgres'\r\n",
                "    password = 'postgres'\r\n",
                "    host = '192.168.11.7'\r\n",
                "    return psycopg2.connect(dbname=dbname, user=user, password=password, host=host)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "@cached(cache=TTLCache(maxsize=32, ttl=60))\r\n",
                "def fetch_aggregated_calibration_data(ignore_outliers = True):\r\n",
                "\twith create_connection() as connection:\r\n",
                "\t\tconnection = create_connection()\r\n",
                "\t\twith connection.cursor() as cursor:\r\n",
                "\t\t\tcursor.execute(f\"\"\"SELECT temperature, humidity, AVG(r0) as r0 \r\n",
                "\t\t\t\tFROM sensor_calibration_data\r\n",
                "\t\t\t\tWHERE device_id = %s AND is_invalid = false {'AND is_outlier = false ' if ignore_outliers else ''}\r\n",
                "\t\t\t\tGROUP BY temperature, humidity \"\"\", (device_id,))\r\n",
                "\t\t\treturn np.array(cursor.fetchall(), dtype=float)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "@cached(cache=TTLCache(maxsize=32, ttl=60))\r\n",
                "def fetch_calibration_data(include_ids = False, ignore_outliers = True):\r\n",
                "\twith create_connection() as connection:\r\n",
                "\t\tconnection = create_connection()\r\n",
                "\t\twith connection.cursor() as cursor:\r\n",
                "\t\t\tcursor.execute(f\"\"\"SELECT {' id, ' if include_ids else ''} temperature, humidity, r0 \r\n",
                "\t\t\t\tFROM sensor_calibration_data \r\n",
                "\t\t\t\tWHERE device_id = %s AND is_invalid = false {'AND is_outlier = false' if ignore_outliers else ''} \"\"\", (device_id,))\r\n",
                "\t\t\treturn np.array(cursor.fetchall(), dtype=float)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def buildModel(degree, train):\r\n",
                "    pipe = make_pipeline(StandardScaler(), PolynomialFeatures(degree), LinearRegression())\r\n",
                "    pipe.fit(train[:,:-1], train[:,-1])\r\n",
                "    return pipe"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def invalidate_out_of_bounds_values():\r\n",
                "    with create_connection() as connection:\r\n",
                "        connection = create_connection()\r\n",
                "        with connection.cursor() as cursor:\r\n",
                "            sqlCommand = \"\"\"\r\n",
                "            UPDATE sensor_calibration_data\r\n",
                "            SET is_invalid = true\r\n",
                "            WHERE device_id = %s AND\r\n",
                "            ( temperature < -40 OR temperature > 80 OR humidity < 0 OR humidity > 100 OR uptime < '20 minutes' )\r\n",
                "            \"\"\"\r\n",
                "            cursor.execute(sqlCommand, (device_id,))\r\n",
                "            connection.commit()\r\n",
                "\r\n",
                "def flag_outliers(ids):\r\n",
                "    with create_connection() as connection:\r\n",
                "        connection = create_connection()\r\n",
                "        with connection.cursor() as cursor:\r\n",
                "            sqlCommand = \"\"\"\r\n",
                "            UPDATE sensor_calibration_data\r\n",
                "            SET is_outlier = true\r\n",
                "            WHERE device_id = %s AND id IN %s\r\n",
                "            \"\"\"\r\n",
                "            cursor.execute(sqlCommand, (device_id, tuple(ids)))\r\n",
                "            connection.commit()\r\n",
                "\r\n",
                "@cached(cache=TTLCache(maxsize=32, ttl=60))\r\n",
                "def fetch_dr0(ignore_outliers = True):\r\n",
                "    with create_connection() as connection:\r\n",
                "        connection = create_connection()\r\n",
                "        with connection.cursor() as cursor:\r\n",
                "            sqlCommand = f\"\"\"\r\n",
                "            WITH data AS (\r\n",
                "                SELECT row_number() OVER () row_id, id, r0, received_at\r\n",
                "                FROM sensor_calibration_data\r\n",
                "                WHERE device_id = %s AND is_invalid = false {'AND is_outlier = false' if ignore_outliers else ''}\r\n",
                "                ORDER BY received_at\r\n",
                "            )\r\n",
                "            SELECT p.id, n.id, (n.r0 - p.r0)/(EXTRACT(EPOCH FROM (n.received_at - p.received_at))) as dr0\r\n",
                "            FROM data n\r\n",
                "            JOIN data p ON (n.row_id = p.row_id + 1 AND n.received_at - p.received_at < interval '5 second')\r\n",
                "            \"\"\"\r\n",
                "            cursor.execute(sqlCommand, (device_id,))\r\n",
                "            return np.array(cursor.fetchall(), dtype=float)\r\n",
                "\r\n",
                "@cached(cache=TTLCache(maxsize=32, ttl=60))\r\n",
                "def fetch_dt(ignore_outliers = True):\r\n",
                "    with create_connection() as connection:\r\n",
                "        connection = create_connection()\r\n",
                "        with connection.cursor() as cursor:\r\n",
                "            sqlCommand = f\"\"\"\r\n",
                "            WITH data AS (\r\n",
                "                SELECT row_number() OVER () row_id, id, temperature, received_at\r\n",
                "                FROM sensor_calibration_data\r\n",
                "                WHERE device_id = %s AND is_invalid = false {'AND is_outlier = false' if ignore_outliers else ''}\r\n",
                "                ORDER BY received_at\r\n",
                "            )\r\n",
                "            SELECT p.id, n.id, (n.temperature - p.temperature)/(EXTRACT(EPOCH FROM (n.received_at - p.received_at))) as dt\r\n",
                "            FROM data n\r\n",
                "            JOIN data p ON (n.row_id = p.row_id + 1 AND n.received_at - p.received_at < interval '5 second')\r\n",
                "            \"\"\"\r\n",
                "            cursor.execute(sqlCommand, (device_id,))\r\n",
                "            return np.array(cursor.fetchall(), dtype=float)\r\n",
                "\r\n",
                "@cached(cache=TTLCache(maxsize=32, ttl=60))\r\n",
                "def fetch_dh(ignore_outliers = True):\r\n",
                "    with create_connection() as connection:\r\n",
                "        connection = create_connection()\r\n",
                "        with connection.cursor() as cursor:\r\n",
                "            sqlCommand = f\"\"\"\r\n",
                "            WITH data AS (\r\n",
                "                SELECT row_number() OVER () row_id, id, humidity, received_at\r\n",
                "                FROM sensor_calibration_data\r\n",
                "                WHERE device_id = %s AND is_invalid = false {'AND is_outlier = false' if ignore_outliers else ''}\r\n",
                "                ORDER BY received_at\r\n",
                "            )\r\n",
                "            SELECT p.id, n.id, (n.humidity - p.humidity)/(EXTRACT(EPOCH FROM (n.received_at - p.received_at))) as dh\r\n",
                "            FROM data n\r\n",
                "            JOIN data p ON (n.row_id = p.row_id + 1 AND n.received_at - p.received_at < interval '5 second')\r\n",
                "            \"\"\"\r\n",
                "            cursor.execute(sqlCommand, (device_id,))\r\n",
                "            return np.array(cursor.fetchall(), dtype=float)\r\n",
                "\r\n",
                "def get_outliers_mask(data, sigmas):\r\n",
                "    data = np.array(data, copy=True)\r\n",
                "    outliers_mask = np.zeros_like(data, dtype=bool)\r\n",
                "    for sigma in sigmas:\r\n",
                "        data = data.reshape(-1, 1)\r\n",
                "        scaler = StandardScaler()\r\n",
                "        scaler.fit(data)\r\n",
                "        data_std = scaler.transform(data).reshape(-1)\r\n",
                "        outliers_mask |= (data_std < -sigma) | (data_std > sigma)\r\n",
                "        data[outliers_mask] = data.mean()\r\n",
                "    return outliers_mask\r\n",
                "\r\n",
                "def mark_outliers_by_dr0():\r\n",
                "    data = fetch_dr0(ignore_outliers = False)\r\n",
                "\r\n",
                "    outliers_mask =  get_outliers_mask(data[:,2], [5, 2])\r\n",
                "    outliers_id = data[outliers_mask, :2].astype(int).flatten().tolist()\r\n",
                "\r\n",
                "    if outliers_id:\r\n",
                "        flag_outliers(outliers_id)\r\n",
                "\r\n",
                "def mark_outliers_by_dt():\r\n",
                "    data = fetch_dt(ignore_outliers = False)\r\n",
                "\r\n",
                "    outliers_mask =  get_outliers_mask(data[:,2], [5, 2])\r\n",
                "    outliers_id = data[outliers_mask, :2].astype(int).flatten().tolist()\r\n",
                "\r\n",
                "    if outliers_id:\r\n",
                "        flag_outliers(outliers_id)\r\n",
                "\r\n",
                "def mark_outliers_by_dh():\r\n",
                "    data = fetch_dh(ignore_outliers = False)\r\n",
                "\r\n",
                "    outliers_mask =  get_outliers_mask(data[:,2], [5, 2])\r\n",
                "    outliers_id = data[outliers_mask, :2].astype(int).flatten().tolist()\r\n",
                "\r\n",
                "    if outliers_id:\r\n",
                "        flag_outliers(outliers_id)\r\n",
                "\r\n",
                "def mark_outliers_by_model():\r\n",
                "    data = fetch_calibration_data(include_ids=True, ignore_outliers=False)\r\n",
                "\r\n",
                "    model = buildModel(2, data[:,1:])\r\n",
                "    predicted_r0 = model.predict(data[:, 1:3])\r\n",
                "\r\n",
                "    outliers_mask =  get_outliers_mask(data[:,3] - predicted_r0, [5])\r\n",
                "    outliers_id = data[outliers_mask, 0].astype(int).flatten().tolist()\r\n",
                "    if outliers_id:\r\n",
                "        flag_outliers(outliers_id)\r\n",
                "\r\n",
                "def clean_up():\r\n",
                "    invalidate_out_of_bounds_values()\r\n",
                "    mark_outliers_by_dr0()\r\n",
                "    mark_outliers_by_dt()\r\n",
                "    mark_outliers_by_dh()\r\n",
                "    mark_outliers_by_model()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "clean_up()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "invalidate_out_of_bounds_values()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "mark_outliers_by_dr0()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "mark_outliers_by_dt()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "mark_outliers_by_dh()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "mark_outliers_by_model()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "plt.figure(figsize=(20, 15))\r\n",
                "\r\n",
                "data = fetch_aggregated_calibration_data(ignore_outliers=True)\r\n",
                "x = data[:,2].reshape(-1, 1)\r\n",
                "\r\n",
                "scaler = StandardScaler()\r\n",
                "scaler.fit(x)\r\n",
                "x = scaler.transform(x)\r\n",
                "\r\n",
                "# the histogram of the data\r\n",
                "n, bins, patches = plt.hist(x, 100, density=True, facecolor='g', alpha=0.75)\r\n",
                "\r\n",
                "plt.grid(True)\r\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "plt.figure(figsize=(20, 15))\r\n",
                "\r\n",
                "data = fetch_dt(ignore_outliers=True)\r\n",
                "x = data[:,2].reshape(-1, 1)\r\n",
                "\r\n",
                "scaler = StandardScaler()\r\n",
                "scaler.fit(x)\r\n",
                "x = scaler.transform(x)\r\n",
                "\r\n",
                "# the histogram of the data\r\n",
                "n, bins, patches = plt.hist(x, 30, density=True, facecolor='g', alpha=0.75)\r\n",
                "\r\n",
                "plt.grid(True)\r\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "plt.figure(figsize=(20, 15))\r\n",
                "\r\n",
                "data = fetch_dr0(ignore_outliers=True)\r\n",
                "x = data[:,2].reshape(-1, 1)\r\n",
                "\r\n",
                "scaler = StandardScaler()\r\n",
                "scaler.fit(x)\r\n",
                "x = scaler.transform(x)\r\n",
                "\r\n",
                "# the histogram of the data\r\n",
                "n, bins, patches = plt.hist(x, 30, density=True, facecolor='g', alpha=0.75)\r\n",
                "\r\n",
                "plt.grid(True)\r\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def runExperiment(degree, aggregated_data, ignore_outliers):\r\n",
                "    data = fetch_aggregated_calibration_data(ignore_outliers) if aggregated_data else fetch_calibration_data(ignore_outliers)\r\n",
                "    train, test = train_test_split(data)    \r\n",
                "    pipe = buildModel(degree, train)\r\n",
                "    train_score = pipe.score(train[:,:-1], train[:,-1])\r\n",
                "    test_score = pipe.score(test[:,:-1], test[:,-1])\r\n",
                "    return (train_score, test_score)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "param_grid = {'degree': [1, 2, 3], 'aggregated_data': [True], 'ignore_outliers': [True, False] }\r\n",
                "\r\n",
                "results = [(test_case, runExperiment(**test_case))for test_case in ParameterGrid(param_grid)]\r\n",
                "results.sort(key=lambda p: p[1][1], reverse=True)\r\n",
                "for result in results:\r\n",
                "        print(result)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "data = fetch_calibration_data(include_ids=True, ignore_outliers=True)\r\n",
                "model = buildModel(2, data[:,1:])\r\n",
                "predicted_r0 = model.predict(data[:, 1:3])\r\n",
                "error = (data[:,3] - predicted_r0).reshape(-1, 1)\r\n",
                "\r\n",
                "scaler = StandardScaler()\r\n",
                "scaler.fit(error)\r\n",
                "std_error = scaler.transform(error).reshape(-1)\r\n",
                "\r\n",
                "outliers_mask = (std_error < -5) | (std_error > 5)\r\n",
                "std_error = std_error[~outliers_mask]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "plt.figure(figsize=(20, 15))\r\n",
                "\r\n",
                "x = std_error.reshape(-1, 1)\r\n",
                "\r\n",
                "# the histogram of the data\r\n",
                "n, bins, patches = plt.hist(x, 100, density=True, facecolor='g', alpha=0.75)\r\n",
                "\r\n",
                "plt.grid(True)\r\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "plot_data = fetch_aggregated_calibration_data(ignore_outliers=True)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "model = buildModel(2, plot_data)\r\n",
                "model.predict(np.array([[22.1, 79.4]]))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import matplotlib.pyplot as plt\r\n",
                "from mpl_toolkits.mplot3d import Axes3D\r\n",
                "from matplotlib import cm\r\n",
                "from matplotlib.ticker import LinearLocator\r\n",
                "import numpy as np\r\n",
                "\r\n",
                "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\r\n",
                "fig.set_size_inches(20, 15)\r\n",
                "\r\n",
                "min_temperature = plot_data[:,0].min()\r\n",
                "max_temperature = plot_data[:,0].max()\r\n",
                "min_humidity = plot_data[:,1].min()\r\n",
                "max_humidity = plot_data[:,1].max()\r\n",
                "\r\n",
                "# Make data.\r\n",
                "X = np.arange(min_temperature * 0.95, max_temperature * 1.05, 0.1)\r\n",
                "Y = np.arange(min_humidity * 0.95, max_humidity * 1.05, 0.1)\r\n",
                "#print(X, Y)\r\n",
                "X, Y = np.meshgrid(X, Y)\r\n",
                "\r\n",
                "print(X.shape)\r\n",
                "XYpairs = np.dstack([X, Y]).reshape(-1, 2)\r\n",
                "print(XYpairs.shape)\r\n",
                "Z = model.predict(XYpairs)\r\n",
                "Z = Z.reshape(X.shape)\r\n",
                "\r\n",
                "# Plot the surface.\r\n",
                "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\r\n",
                "                       linewidth=0, antialiased=True)\r\n",
                "\r\n",
                "\r\n",
                "# Add a color bar which maps values to colors.\r\n",
                "fig.colorbar(surf, shrink=0.5, aspect=5)\r\n",
                "\r\n",
                "#plot_dots = plot_data\r\n",
                "#print(plot_dots.shape)\r\n",
                "#ax.scatter(plot_dots[:,0], plot_dots[:,1], plot_dots[:,2], cmap=cm.coolwarm )\r\n",
                "\r\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "plt.figure(figsize=(20, 15))\r\n",
                "\r\n",
                "zdata = plot_data[:,-1]\r\n",
                "xdata = plot_data[:, 0]\r\n",
                "ydata = plot_data[:, 1]\r\n",
                "scatter = plt.scatter(xdata, ydata, c=zdata, cmap=cm.coolwarm);\r\n",
                "plt.colorbar(scatter)\r\n",
                "#fig.colorbar(surf, shrink=0.5, aspect=5)\r\n",
                "#type(scatter)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.3 64-bit ('torch': conda)"
        },
        "interpreter": {
            "hash": "06fd2f3151bfea81d419f9a472826ce194eae6884a3cf8264ef7dab6f864be4e"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}