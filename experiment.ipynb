{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 29,
            "source": [
                "! pip install psycopg2\r\n",
                "! pip install sklearn\r\n",
                "\r\n",
                "import psycopg2\r\n",
                "\r\n",
                "import numpy as np\r\n",
                "\r\n",
                "from sklearn.pipeline import make_pipeline\r\n",
                "from sklearn.model_selection import train_test_split, ParameterGrid\r\n",
                "from sklearn.preprocessing import StandardScaler\r\n",
                "from sklearn.preprocessing import PolynomialFeatures\r\n",
                "from sklearn.linear_model import LinearRegression\r\n",
                "\r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Requirement already satisfied: psycopg2 in c:\\users\\gruzilkin\\anaconda3\\envs\\torch\\lib\\site-packages (2.9.1)\n",
                        "Requirement already satisfied: sklearn in c:\\users\\gruzilkin\\anaconda3\\envs\\torch\\lib\\site-packages (0.0)\n",
                        "Requirement already satisfied: scikit-learn in c:\\users\\gruzilkin\\anaconda3\\envs\\torch\\lib\\site-packages (from sklearn) (0.24.2)\n",
                        "Requirement already satisfied: joblib>=0.11 in c:\\users\\gruzilkin\\anaconda3\\envs\\torch\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
                        "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\gruzilkin\\anaconda3\\envs\\torch\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
                        "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gruzilkin\\anaconda3\\envs\\torch\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
                        "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\gruzilkin\\anaconda3\\envs\\torch\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "device_id = \"iskra\""
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def create_connection():\r\n",
                "    dbname = 'postgres'\r\n",
                "    user = 'postgres'\r\n",
                "    password = 'postgres'\r\n",
                "    host = '192.168.11.17'\r\n",
                "    return psycopg2.connect(dbname=dbname, user=user, password=password, host=host)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def fetch_aggregated_calibration_data():\r\n",
                "\twith create_connection() as connection:\r\n",
                "\t\tconnection = create_connection()\r\n",
                "\t\twith connection.cursor() as cursor:\r\n",
                "\t\t\tcursor.execute(f\"SELECT temperature, humidity, AVG(r0) as r0 \" \\\r\n",
                "\t\t\t\t\"FROM sensor_calibration_data \" \\\r\n",
                "\t\t\t\t\"WHERE device_id = %s \"\r\n",
                "\t\t\t\t\"GROUP BY temperature, humidity \", (device_id,))\r\n",
                "\t\t\treturn np.array(cursor.fetchall(), dtype=float)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def fetch_calibration_data():\r\n",
                "\twith create_connection() as connection:\r\n",
                "\t\tconnection = create_connection()\r\n",
                "\t\twith connection.cursor() as cursor:\r\n",
                "\t\t\tcursor.execute(f\"SELECT temperature, humidity, r0 \" \\\r\n",
                "\t\t\t\t\"FROM sensor_calibration_data \" \\\r\n",
                "\t\t\t\t\"WHERE r0 > 40 AND device_id = %s \", (device_id,))\r\n",
                "\t\t\treturn np.array(cursor.fetchall(), dtype=float)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def fetch_calibration_data_with_id():\r\n",
                "\twith create_connection() as connection:\r\n",
                "\t\tconnection = create_connection()\r\n",
                "\t\twith connection.cursor() as cursor:\r\n",
                "\t\t\tcursor.execute(f\"SELECT id, temperature, humidity, r0 \" \\\r\n",
                "\t\t\t\t\"FROM sensor_calibration_data \" \\\r\n",
                "\t\t\t\t\"WHERE r0 > 40 AND device_id = %s \", (device_id,))\r\n",
                "\t\t\treturn np.array(cursor.fetchall(), dtype=float)\r\n",
                "\r\n",
                "def fetch_r0_change_data():\r\n",
                "\twith create_connection() as connection:\r\n",
                "\t\tconnection = create_connection()\r\n",
                "\t\twith connection.cursor() as cursor:\r\n",
                "\t\t\tsqlCommand = \"\"\"\r\n",
                "WITH data AS (\r\n",
                "\tSELECT row_number() OVER () row_id, id, temperature, humidity, r0, received_at\r\n",
                "\tFROM sensor_calibration_data\r\n",
                "\tWHERE device_id = %s\r\n",
                "\tORDER BY received_at\r\n",
                ")\r\n",
                "SELECT p.id, (n.r0 - p.r0)/(EXTRACT(EPOCH FROM (n.received_at - p.received_at))) as dr0\r\n",
                "FROM data n\r\n",
                "JOIN data p ON (n.row_id = p.row_id + 1)\r\n",
                "WHERE n.received_at - p.received_at < interval '1 minute';\r\n",
                "\"\"\"\r\n",
                "\t\t\tcursor.execute(sqlCommand, (device_id,))\r\n",
                "\t\t\treturn np.array(cursor.fetchall(), dtype=float)\r\n",
                "\r\n",
                "def get_outliers():\r\n",
                "    data = fetch_r0_change_data()\r\n",
                "    r0_change = data[:,1].reshape(-1, 1)\r\n",
                "    scaler = StandardScaler()\r\n",
                "    scaler.fit(r0_change)\r\n",
                "    r0_change_standard = scaler.transform(r0_change)\r\n",
                "    extended_data = np.hstack((data, r0_change_standard))\r\n",
                "    outliers_mask = (extended_data[:, 2] < -5) | (extended_data[:, 2] > 5)\r\n",
                "    outliers_id = data[outliers_mask][:, 0].astype(int)\r\n",
                "    return outliers_id\r\n",
                "\r\n",
                "def clean_up_db():\r\n",
                "\toutliers = tuple([row for row in get_outliers().tolist()])\r\n",
                "\twith create_connection() as connection:\r\n",
                "\t\tconnection = create_connection()\r\n",
                "\t\twith connection.cursor() as cursor:\r\n",
                "\t\t\tcursor.execute(f\"DELETE \" \\\r\n",
                "                \"FROM sensor_calibration_data \" \\\r\n",
                "                \"WHERE id in %s\", (outliers,))\r\n",
                "\t\t\tconnection.commit()\r\n",
                "\r\n",
                "\r\n",
                "def fetch_clean_calibration_data():\r\n",
                "\toutliers = get_outliers()\r\n",
                "\tcalibration_data = fetch_calibration_data_with_id()\r\n",
                "\toutliers_mask = np.isin(calibration_data[:, 0], outliers)\r\n",
                "\treturn calibration_data[~outliers_mask][:, 1:]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "len(get_outliers())"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#if len(get_outliers()) > 0:\r\n",
                "#    clean_up_db()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "data = fetch_r0_change_data()\r\n",
                "\r\n",
                "x = data[:,1].reshape(-1, 1)\r\n",
                "scaler = StandardScaler()\r\n",
                "scaler.fit(x)\r\n",
                "x = scaler.transform(x)\r\n",
                "\r\n",
                "#extended = np.hstack((data, x))\r\n",
                "#mask = (extended[:, 2] > 5) | (extended[:, 2] < -5)\r\n",
                "#outliers = extended[mask]\r\n",
                "#x = data[~mask][:,1].reshape(-1, 1)\r\n",
                "\r\n",
                "mask = (x < -5) | (x > 5) \r\n",
                "x = data[:,1].reshape(-1, 1)\r\n",
                "x = x[~mask]\r\n",
                "\r\n",
                "# the histogram of the data\r\n",
                "n, bins, patches = plt.hist(x, density=True, facecolor='g', alpha=0.75)\r\n",
                "\r\n",
                "plt.grid(True)\r\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def aggregateData(train):\r\n",
                "    grouped = {}\r\n",
                "    for t, h, r0 in train:\r\n",
                "        if (t , h) in grouped.keys():\r\n",
                "            grouped[(t, h)].append(r0)\r\n",
                "        else:\r\n",
                "            grouped[(t, h)] = [r0]\r\n",
                "    averaged = [(t, h, sum(grouped[(t, h)]) / len(grouped[(t, h)])) for (t, h) in grouped.keys()]\r\n",
                "    return np.array(averaged, dtype=float)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def buildModel(degree, train):\r\n",
                "    pipe = make_pipeline(StandardScaler(), PolynomialFeatures(degree), LinearRegression())\r\n",
                "    pipe.fit(train[:,:-1], train[:,-1])\r\n",
                "    return pipe"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def runExperiment(degree = 2, aggregate_train_data = False, clean_data = False):\r\n",
                "    data = fetch_clean_calibration_data() if clean_data else fetch_calibration_data()\r\n",
                "    data = aggregateData(data) if aggregate_train_data else data\r\n",
                "    train, test = train_test_split(data)    \r\n",
                "    pipe = buildModel(degree, train)\r\n",
                "    train_score = pipe.score(train[:,:-1], train[:,-1])\r\n",
                "    test_score = pipe.score(test[:,:-1], test[:,-1])\r\n",
                "    return (train_score, test_score)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "param_grid = {'degree': [1, 2, 3], 'aggregate_train_data': [True], 'clean_data': [True, False] }\r\n",
                "\r\n",
                "results = [(test_case, runExperiment(**test_case))for test_case in ParameterGrid(param_grid)]\r\n",
                "results.sort(key=lambda p: p[1][1], reverse=True)\r\n",
                "for result in results:\r\n",
                "        print(result)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "plot_data = fetch_aggregated_calibration_data()\r\n",
                "#model = buildModel(2, aggregateData(plot_data))\r\n",
                "#model = buildModel(10, plot_data)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "model = buildModel(2, plot_data)\r\n",
                "model.predict(np.array([[23.7, 85.4]]))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import matplotlib.pyplot as plt\r\n",
                "from mpl_toolkits.mplot3d import Axes3D\r\n",
                "from matplotlib import cm\r\n",
                "from matplotlib.ticker import LinearLocator\r\n",
                "import numpy as np\r\n",
                "\r\n",
                "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\r\n",
                "fig.set_size_inches(20, 15)\r\n",
                "\r\n",
                "# Make data.\r\n",
                "X = np.arange(10, 50, 1)\r\n",
                "Y = np.arange(20, 100, 1)\r\n",
                "#print(X, Y)\r\n",
                "X, Y = np.meshgrid(X, Y)\r\n",
                "\r\n",
                "print(X.shape)\r\n",
                "XYpairs = np.dstack([X, Y]).reshape(-1, 2)\r\n",
                "print(XYpairs.shape)\r\n",
                "Z = model.predict(XYpairs)\r\n",
                "Z = Z.reshape(X.shape)\r\n",
                "\r\n",
                "# Plot the surface.\r\n",
                "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\r\n",
                "                       linewidth=0, antialiased=True)\r\n",
                "\r\n",
                "# Customize the z axis.\r\n",
                "#ax.set_zlim(-1.01, 1.01)\r\n",
                "#ax.zaxis.set_major_locator(LinearLocator(10))\r\n",
                "\r\n",
                "# Add a color bar which maps values to colors.\r\n",
                "fig.colorbar(surf, shrink=0.5, aspect=5)\r\n",
                "\r\n",
                "#plot_dots = plot_data\r\n",
                "#print(plot_dots.shape)\r\n",
                "#ax.scatter(plot_dots[:,0], plot_dots[:,1], plot_dots[:,2], cmap=cm.coolwarm )\r\n",
                "\r\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "zdata = plot_data[:,-1]\r\n",
                "xdata = plot_data[:, 0]\r\n",
                "ydata = plot_data[:, 1]\r\n",
                "plt.scatter(xdata, ydata, c=zdata, cmap=cm.coolwarm);"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.3 64-bit ('torch': conda)"
        },
        "interpreter": {
            "hash": "06fd2f3151bfea81d419f9a472826ce194eae6884a3cf8264ef7dab6f864be4e"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}