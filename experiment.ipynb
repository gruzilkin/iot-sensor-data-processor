{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "! pip install psycopg2\r\n",
                "! pip install sklearn\r\n",
                "\r\n",
                "import psycopg2\r\n",
                "\r\n",
                "import numpy as np\r\n",
                "\r\n",
                "from sklearn.pipeline import make_pipeline\r\n",
                "from sklearn.model_selection import train_test_split, ParameterGrid\r\n",
                "from sklearn.preprocessing import StandardScaler\r\n",
                "from sklearn.preprocessing import PolynomialFeatures\r\n",
                "from sklearn.linear_model import LinearRegression\r\n",
                "\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "device_id = \"iskra\""
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def create_connection():\r\n",
                "    dbname = 'postgres'\r\n",
                "    user = 'postgres'\r\n",
                "    password = 'postgres'\r\n",
                "    host = '192.168.11.17'\r\n",
                "    return psycopg2.connect(dbname=dbname, user=user, password=password, host=host)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def fetch_aggregated_calibration_data(ignore_outliers = True):\r\n",
                "\twith create_connection() as connection:\r\n",
                "\t\tconnection = create_connection()\r\n",
                "\t\twith connection.cursor() as cursor:\r\n",
                "\t\t\tcursor.execute(f\"\"\"SELECT temperature, humidity, AVG(r0) as r0 \r\n",
                "\t\t\t\tFROM sensor_calibration_data\r\n",
                "\t\t\t\tWHERE device_id = %s {'AND is_outlier = false ' if ignore_outliers else ''}\r\n",
                "\t\t\t\tGROUP BY temperature, humidity \"\"\", (device_id,))\r\n",
                "\t\t\treturn np.array(cursor.fetchall(), dtype=float)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def fetch_calibration_data(ignore_outliers = True):\r\n",
                "\twith create_connection() as connection:\r\n",
                "\t\tconnection = create_connection()\r\n",
                "\t\twith connection.cursor() as cursor:\r\n",
                "\t\t\tcursor.execute(f\"\"\"SELECT temperature, humidity, r0 \r\n",
                "\t\t\t\tFROM sensor_calibration_data \r\n",
                "\t\t\t\tWHERE device_id = %s {'AND is_outlier = false' if ignore_outliers else ''} \"\"\", (device_id,))\r\n",
                "\t\t\treturn np.array(cursor.fetchall(), dtype=float)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def invalidate_out_of_bounds_values():\r\n",
                "    with create_connection() as connection:\r\n",
                "        connection = create_connection()\r\n",
                "        with connection.cursor() as cursor:\r\n",
                "            sqlCommand = \"\"\"\r\n",
                "            UPDATE sensor_calibration_data\r\n",
                "            SET is_outlier = true\r\n",
                "            WHERE device_id = %s AND\r\n",
                "            ( temperature < -40 OR temperature > 80 OR humidity < 0 OR humidity > 100 OR uptime < '20 minutes' )\r\n",
                "            \"\"\"\r\n",
                "            cursor.execute(sqlCommand, (device_id,))\r\n",
                "            connection.commit()\r\n",
                "\r\n",
                "def invalidate_ids(ids):\r\n",
                "    with create_connection() as connection:\r\n",
                "        connection = create_connection()\r\n",
                "        with connection.cursor() as cursor:\r\n",
                "            sqlCommand = \"\"\"\r\n",
                "            UPDATE sensor_calibration_data\r\n",
                "            SET is_outlier = true\r\n",
                "            WHERE device_id = %s AND id IN %s\r\n",
                "            \"\"\"\r\n",
                "            cursor.execute(sqlCommand, (device_id, tuple(ids)))\r\n",
                "            connection.commit()\r\n",
                "\r\n",
                "def invalidate_loners():\r\n",
                "    with create_connection() as connection:\r\n",
                "        connection = create_connection()\r\n",
                "        with connection.cursor() as cursor:\r\n",
                "            sqlCommand = \"\"\"\r\n",
                "            WITH data AS (\r\n",
                "                SELECT row_number() OVER () row_id, id, received_at\r\n",
                "                FROM sensor_calibration_data\r\n",
                "                WHERE device_id = %s\r\n",
                "                ORDER BY received_at\r\n",
                "            ),\r\n",
                "            tails AS (\r\n",
                "                SELECT n.id\r\n",
                "                FROM data n\r\n",
                "                LEFT JOIN data p ON (n.row_id = p.row_id + 1 AND n.received_at - p.received_at < interval '5 second')\r\n",
                "                WHERE p.id IS NULL\r\n",
                "            ),\r\n",
                "            heads AS (\r\n",
                "                SELECT p.id\r\n",
                "                FROM data p\r\n",
                "                LEFT JOIN data n ON (n.row_id = p.row_id + 1 AND n.received_at - p.received_at < interval '5 second')\r\n",
                "                WHERE n.id IS NULL\r\n",
                "            ),\r\n",
                "            loners AS (\r\n",
                "                SELECT t.id\r\n",
                "                FROM tails t\r\n",
                "                JOIN heads h ON (t.id = h.id)\r\n",
                "            )\r\n",
                "            UPDATE sensor_calibration_data\r\n",
                "            SET is_outlier = true\r\n",
                "            WHERE id IN (SELECT id FROM loners)\r\n",
                "            \"\"\"\r\n",
                "            cursor.execute(sqlCommand, (device_id,))\r\n",
                "            connection.commit()\r\n",
                "\r\n",
                "def fetch_dr0(ignore_outliers = True):\r\n",
                "    with create_connection() as connection:\r\n",
                "        connection = create_connection()\r\n",
                "        with connection.cursor() as cursor:\r\n",
                "            sqlCommand = f\"\"\"\r\n",
                "            WITH data AS (\r\n",
                "                SELECT row_number() OVER () row_id, id, r0, received_at\r\n",
                "                FROM sensor_calibration_data\r\n",
                "                WHERE device_id = %s {'AND is_outlier = false' if ignore_outliers else ''}\r\n",
                "                ORDER BY received_at\r\n",
                "            )\r\n",
                "            SELECT p.id, n.id, (n.r0 - p.r0)/(EXTRACT(EPOCH FROM (n.received_at - p.received_at))) as dr0\r\n",
                "            FROM data n\r\n",
                "            JOIN data p ON (n.row_id = p.row_id + 1 AND n.received_at - p.received_at < interval '5 second')\r\n",
                "            \"\"\"\r\n",
                "            cursor.execute(sqlCommand, (device_id,))\r\n",
                "            return np.array(cursor.fetchall(), dtype=float)\r\n",
                "\r\n",
                "def get_outliers():\r\n",
                "    data = fetch_dr0()\r\n",
                "\r\n",
                "    dr0 = data[:,2].reshape(-1, 1)\r\n",
                "    scaler = StandardScaler()\r\n",
                "    scaler.fit(dr0)\r\n",
                "    dr0_std = scaler.transform(dr0).reshape(-1)\r\n",
                "\r\n",
                "    outliers_mask = (dr0_std < -5) | (dr0_std > 5)\r\n",
                "    outliers_id = data[outliers_mask][:, :2].astype(int).flatten().tolist()\r\n",
                "\r\n",
                "    return set(outliers_id)\r\n",
                "\r\n",
                "def invalidate_outliers():\r\n",
                "    outliers = get_outliers()\r\n",
                "    if outliers:\r\n",
                "        invalidate_ids(outliers)\r\n",
                "\r\n",
                "def clean_up():\r\n",
                "    invalidate_out_of_bounds_values()\r\n",
                "    invalidate_outliers()\r\n",
                "    invalidate_loners()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "invalidate_out_of_bounds_values()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "invalidate_outliers()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "invalidate_loners()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "clean_up()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "plt.figure(figsize=(20, 15))\r\n",
                "\r\n",
                "data = fetch_dr0(ignore_outliers=True)\r\n",
                "x = data[:,2].reshape(-1, 1)\r\n",
                "\r\n",
                "scaler = StandardScaler()\r\n",
                "scaler.fit(x)\r\n",
                "x = scaler.transform(x)\r\n",
                "\r\n",
                "# the histogram of the data\r\n",
                "n, bins, patches = plt.hist(x, 30, density=True, facecolor='g', alpha=0.75)\r\n",
                "\r\n",
                "plt.grid(True)\r\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def buildModel(degree, train):\r\n",
                "    pipe = make_pipeline(StandardScaler(), PolynomialFeatures(degree), LinearRegression())\r\n",
                "    pipe.fit(train[:,:-1], train[:,-1])\r\n",
                "    return pipe"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def runExperiment(degree, aggregated_data, ignore_outliers):\r\n",
                "    data = fetch_aggregated_calibration_data(ignore_outliers) if aggregated_data else fetch_calibration_data(ignore_outliers)\r\n",
                "    train, test = train_test_split(data)    \r\n",
                "    pipe = buildModel(degree, train)\r\n",
                "    train_score = pipe.score(train[:,:-1], train[:,-1])\r\n",
                "    test_score = pipe.score(test[:,:-1], test[:,-1])\r\n",
                "    return (train_score, test_score)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "param_grid = {'degree': [1, 2, 3, 4, 5], 'aggregated_data': [True], 'ignore_outliers': [True, False] }\r\n",
                "\r\n",
                "results = [(test_case, runExperiment(**test_case))for test_case in ParameterGrid(param_grid)]\r\n",
                "results.sort(key=lambda p: p[1][1], reverse=True)\r\n",
                "for result in results:\r\n",
                "        print(result)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "plot_data = fetch_aggregated_calibration_data()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "model = buildModel(2, plot_data)\r\n",
                "model.predict(np.array([[23.7, 85.4]]))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import matplotlib.pyplot as plt\r\n",
                "from mpl_toolkits.mplot3d import Axes3D\r\n",
                "from matplotlib import cm\r\n",
                "from matplotlib.ticker import LinearLocator\r\n",
                "import numpy as np\r\n",
                "\r\n",
                "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\r\n",
                "fig.set_size_inches(20, 15)\r\n",
                "\r\n",
                "# Make data.\r\n",
                "X = np.arange(10, 50, 1)\r\n",
                "Y = np.arange(20, 100, 1)\r\n",
                "#print(X, Y)\r\n",
                "X, Y = np.meshgrid(X, Y)\r\n",
                "\r\n",
                "print(X.shape)\r\n",
                "XYpairs = np.dstack([X, Y]).reshape(-1, 2)\r\n",
                "print(XYpairs.shape)\r\n",
                "Z = model.predict(XYpairs)\r\n",
                "Z = Z.reshape(X.shape)\r\n",
                "\r\n",
                "# Plot the surface.\r\n",
                "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\r\n",
                "                       linewidth=0, antialiased=True)\r\n",
                "\r\n",
                "\r\n",
                "# Add a color bar which maps values to colors.\r\n",
                "fig.colorbar(surf, shrink=0.5, aspect=5)\r\n",
                "\r\n",
                "#plot_dots = plot_data\r\n",
                "#print(plot_dots.shape)\r\n",
                "#ax.scatter(plot_dots[:,0], plot_dots[:,1], plot_dots[:,2], cmap=cm.coolwarm )\r\n",
                "\r\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "zdata = plot_data[:,-1]\r\n",
                "xdata = plot_data[:, 0]\r\n",
                "ydata = plot_data[:, 1]\r\n",
                "plt.scatter(xdata, ydata, c=zdata, cmap=cm.coolwarm);"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.3 64-bit ('torch': conda)"
        },
        "interpreter": {
            "hash": "06fd2f3151bfea81d419f9a472826ce194eae6884a3cf8264ef7dab6f864be4e"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}